# DailyRH Leave Planning Scraper

Solution d'extraction automatisÃ©e des donnÃ©es de planning de congÃ©s depuis DailyRH (BNP Paribas) avec gÃ©nÃ©ration de rapports Excel analytiques.

## ğŸ“‹ Vue d'ensemble

Ce projet permet de :
- **Extraire** automatiquement les plannings de congÃ©s de tous les collaborateurs
- **Analyser** les donnÃ©es selon les rÃ¨gles RH (10j consÃ©cutifs, 20j total sur pÃ©riode)
- **GÃ©nÃ©rer** des rapports Excel formatÃ©s avec synthÃ¨ses et calendriers

## ğŸ—ï¸ Architecture

```
dailyrh_scraper/
â”œâ”€â”€ src/                    # Code source principal
â”‚   â”œâ”€â”€ config/            # Configuration et constantes
â”‚   â”œâ”€â”€ logging/           # SystÃ¨me de logging
â”‚   â”œâ”€â”€ utils/             # Fonctions utilitaires
â”‚   â”œâ”€â”€ scraper/           # Logique d'extraction
â”‚   â””â”€â”€ excel/             # GÃ©nÃ©ration de rapports
â”œâ”€â”€ scripts/               # Scripts exÃ©cutables
â”‚   â”œâ”€â”€ main.py           # Script principal
â”‚   â””â”€â”€ save_session.py   # Sauvegarde session SSO
â”œâ”€â”€ output/                # Fichiers gÃ©nÃ©rÃ©s (CSV, Excel)
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ requirements.txt       # DÃ©pendances Python
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- AccÃ¨s Ã  DailyRH (compte BNP Paribas)

### Installation des dÃ©pendances

```bash
# 1. Cloner ou extraire le projet
cd dailyrh_scraper

# 2. Installer les dÃ©pendances Python
pip install -r requirements.txt

# 3. Installer le navigateur Chromium pour Playwright
playwright install chromium
```

## ğŸ“– Utilisation

### PremiÃ¨re utilisation

#### 1. Sauvegarder la session SSO

```bash
python scripts/save_session.py
```

**Ce qu'il se passe :**
1. Un navigateur Chrome s'ouvre
2. Connectez-vous manuellement au SSO BNP Paribas
3. Appuyez sur ENTRÃ‰E dans le terminal une fois connectÃ©
4. La session est sauvegardÃ©e

âš ï¸ **Cette Ã©tape n'est Ã  faire qu'une seule fois** (ou quand la session expire).

#### 2. Lancer le scraping

```bash
python scripts/main.py
```

**Le script va :**
1. Charger DailyRH avec votre session sauvegardÃ©e
2. Naviguer automatiquement vers janvier 2026
3. Extraire les donnÃ©es de tous les mois
4. GÃ©nÃ©rer un CSV et un Excel dans `output/`

**DurÃ©e** : 15-20 minutes selon le nombre de collaborateurs

### ExÃ©cutions suivantes

Une fois la session sauvegardÃ©e, il suffit d'exÃ©cuter :

```bash
python scripts/main.py
```

## ğŸ“Š Fichiers gÃ©nÃ©rÃ©s

Tous les fichiers sont crÃ©Ã©s dans le rÃ©pertoire `output/` :

| Fichier | Description |
|---------|-------------|
| `leave_planning_2026.csv` | DonnÃ©es brutes au format CSV |
| `rapport_conges_2026.xlsx` | Rapport Excel complet avec analyses |

### Structure du CSV

```csv
collaborateur,uid,date,type_am,detail_am,type_pm,detail_pm
Dupont Jean,123456,2026/01/15,CONGES,CongÃ©s (ValidÃ©),CONGES,CongÃ©s (ValidÃ©)
```

### Contenu du rapport Excel

**Feuille "SynthÃ¨se"**
- Compteurs par collaborateur (tÃ©lÃ©travail, congÃ©s, RTT)
- Validation des rÃ¨gles RH (10j consÃ©cutifs, 20j total)
- Totaux et statistiques globales

**Feuilles mensuelles** (Janvier, FÃ©vrier, ...)
- Vue par mois avec collaborateurs en lignes
- Codes couleur pour chaque type d'Ã©vÃ©nement
- Totaux en bas de page

**Feuilles individuelles** (une par collaborateur)
- Calendrier annuel complet (12 mois Ã— 31 jours)
- Vue d'ensemble du planning de l'annÃ©e

## ğŸ¨ Codes Excel

| Code | Signification | Couleur |
|------|---------------|---------|
| `CV` | CongÃ©s validÃ©s | ğŸŸ¢ Vert |
| `CP` | CongÃ©s Ã  valider | ğŸŸ¡ Vert clair |
| `RV` | RTT validÃ©s | ğŸŸ  Orange |
| `RP` | RTT Ã  valider | ğŸŸ¡ Orange clair |
| `TV` | TÃ©lÃ©travail validÃ© | ğŸ”µ Bleu |
| `TP` | TÃ©lÃ©travail Ã  valider | ğŸ”µ Bleu clair |
| `W` | Week-end / FÃ©riÃ© | âš« Gris |
| `CV-AM` | CongÃ©s matin uniquement | ğŸŸ¢ |
| `TV-PM` | TÃ©lÃ©travail aprÃ¨s-midi | ğŸ”µ |
| `CV/TV` | Matin â‰  aprÃ¨s-midi | âšª Mixte |

## âš™ï¸ Configuration

La configuration se trouve dans `src/config/config.py`. Vous pouvez modifier :

```python
# AnnÃ©e Ã  extraire
TARGET_YEAR = 2026

# Mode sans interface graphique
HEADLESS_MODE = False  # True pour exÃ©cution serveur

# DÃ©lais de navigation (en secondes)
NAVIGATION_DELAY = 1.5
INITIAL_LOAD_DELAY = 10

# RÃ¨gles RH
RULE_MIN_CONSECUTIVE_DAYS = 10
RULE_MIN_TOTAL_DAYS = 20

# Noms des fichiers de sortie
OUTPUT_CSV = "leave_planning_2026.csv"
OUTPUT_EXCEL = "rapport_conges_2026.xlsx"
```

## ğŸ” Logging

Le systÃ¨me gÃ©nÃ¨re un fichier `dailyrh_scraper.log` avec :
- Progression du scraping
- Erreurs et avertissements
- Statistiques de collecte

Pour plus de dÃ©tails, modifier le niveau dans `scripts/main.py` :

```python
logger = setup_logger(level="DEBUG")  # Au lieu de "INFO"
```

## ğŸ› ï¸ Maintenance

Pour comprendre le code et apporter des modifications, consultez :

- `docs/MODULES.md` : Explication dÃ©taillÃ©e de chaque module
- `docs/QUICKSTART.md` : Guide de dÃ©marrage rapide

## â“ DÃ©pannage

### Erreur "Session file not found"

**Solution** : ExÃ©cutez d'abord `python scripts/save_session.py`

### Session expirÃ©e

**Solution** : RÃ©-exÃ©cutez `python scripts/save_session.py`

### Timeout / Navigation lente

**Solution** : Augmentez les dÃ©lais dans `src/config/config.py` :
```python
NAVIGATION_DELAY = 3.0
INITIAL_LOAD_DELAY = 15
```

### DonnÃ©es incomplÃ¨tes

**Solution** : Consultez `dailyrh_scraper.log` pour identifier le mois problÃ©matique

## ğŸ”’ SÃ©curitÃ©

**âš ï¸ IMPORTANT :**
- Ne committez JAMAIS `bnpparibas_session.json` (contient vos cookies)
- Ne partagez JAMAIS les fichiers CSV/Excel (donnÃ©es personnelles)
- Le `.gitignore` est configurÃ© pour protÃ©ger ces fichiers

## ğŸ“ Support

Pour toute question :
1. Consultez `dailyrh_scraper.log`
2. Lisez `docs/MODULES.md`
3. Activez le mode DEBUG pour plus de dÃ©tails

## ğŸ“ Licence

Usage interne BNP Paribas uniquement.
